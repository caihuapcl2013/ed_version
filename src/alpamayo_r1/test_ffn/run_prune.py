import torch

from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1
from alpamayo_r1.configs.default import get_config
from prune_ffn_alpamayo import prune_alpamayo_ffn


def main():
    # 1ï¸âƒ£ æ„å»º configï¼ˆAlpamayo åŸç”Ÿï¼‰
    cfg = get_config()

    # 2ï¸âƒ£ æ„å»ºæ¨¡å‹ç»“æ„
    model = AlpamayoR1(cfg).cuda().eval()

    # 3ï¸âƒ£ åŠ è½½ checkpointï¼ˆä¸æ˜¯ HFï¼‰
    ckpt_path = "alpamayo_r1_10b.pth"   # â† ä½ çœŸå®å­˜åœ¨çš„æ–‡ä»¶
    state = torch.load(ckpt_path, map_location="cpu")

    model.load_state_dict(state, strict=True)

    print("âœ… Original checkpoint loaded")

    # 4ï¸âƒ£ FFN å‰ªæï¼ˆç»“æ„å‘ç”Ÿå˜åŒ–ï¼‰
    model = prune_alpamayo_ffn(
        model,
        keep_ratio=0.7,
        verbose=True
    )

    # 5ï¸âƒ£ ä¿å­˜å‰ªæåçš„æƒé‡
    torch.save(
        model.state_dict(),
        "alpamayo_r1_ffn70_pruned.pth"
    )

    print("ğŸ¯ FFN pruned model saved")


if __name__ == "__main__":
    main()
