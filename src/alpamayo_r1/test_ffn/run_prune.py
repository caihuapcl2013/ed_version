
import sys
import torch

# ç¡®ä¿èƒ½ import alpamayo_r1
sys.path.append("/workspace/ed_version/src")

from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1
from prune_ffn_alpamayo import prune_alpamayo_ffn


def main():
    # 1ï¸âƒ£ æ„å»ºæ¨¡å‹ï¼ˆç…§ test_inference.pyï¼‰
    model = AlpamayoR1().cuda().eval()  # æˆ–è€…åŠ ä¸Š test_inference é‡Œéœ€è¦çš„å‚æ•°

    # 2ï¸âƒ£ åŠ è½½ checkpoint
    ckpt_path = "alpamayo_r1_10b.pth"   # â† æ”¹æˆä½ çš„å®é™…è·¯å¾„
    state = torch.load(ckpt_path, map_location="cpu")
    model.load_state_dict(state, strict=True)

    print("âœ… Original checkpoint loaded")

    # 3ï¸âƒ£ FFN å‰ªæ
    model = prune_alpamayo_ffn(
        model,
        keep_ratio=0.7,
        verbose=True
    )

    # 4ï¸âƒ£ ä¿å­˜å‰ªæç»“æœ
    torch.save(
        model.state_dict(),
        "alpamayo_r1_ffn70_pruned.pth"
    )

    print("ğŸ¯ FFN pruned model saved")


if __name__ == "__main__":
    main()
