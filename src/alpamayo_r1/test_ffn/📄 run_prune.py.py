import torch
from prune_ffn_alpamayo import prune_alpamayo_ffn

# âš ï¸ æŒ‰ä½ è‡ªå·±çš„å·¥ç¨‹è·¯å¾„ä¿®æ”¹
from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1


def main():
    # -------- 1. åŠ è½½æ¨¡å‹ --------
    model = AlpamayoR1.from_pretrained(
        "checkpoints/alpamayo_r1_10b"
    ).cuda().eval()

    # -------- 2. FFN å‰ªæ --------
    pruned_model = prune_alpamayo_ffn(
        model,
        keep_ratio=0.7,   # â­ æ¨è 0.7 / 0.75 / 0.8
        verbose=True
    )

    # -------- 3. ä¿å­˜æƒé‡ --------
    torch.save(
        pruned_model.state_dict(),
        "alpamayo_r1_ffn70_pruned.pth"
    )

    print("\nğŸ¯ Pruned model saved.")


if __name__ == "__main__":
    main()
